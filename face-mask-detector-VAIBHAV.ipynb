{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/face-mask-detection/images'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport xml.etree.ElementTree as et\nimport re\nimport pandas as pd\n\ndic = {\"image\": [],\"Dimensions\": []}\nfor i in range(1,116):\n\tdic[f'Object {i}']=[]\nprint(\"Generating data in CSV format....\")\n\nfor file in os.listdir(\"/kaggle/input/face-mask-detection/annotations\"):\n    row = []\n    xml = et.parse(\"/kaggle/input/face-mask-detection/annotations/\"+file) \n    root = xml.getroot()\n    img = root[1].text\n    row.append(img)\n    h,w = root[2][0].text,root[2][1].text\n    row.append([h,w])\n\n    for i in range(4,len(root)):\n        temp = []\n        temp.append(root[i][0].text)\n        for point in root[i][5]:\n            temp.append(point.text)\n        row.append(temp)\n    for i in range(len(row),119):\n        row.append(0)\n    for i,each in enumerate(dic):\n        dic[each].append(row[i])\ndf = pd.DataFrame(dic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport pandas as pd\nimport glob\nimport os\nimport cv2\nimport random as rand\n\nimage_directories = sorted(glob.glob(os.path.join(\"/kaggle/input/face-mask-detection/images\",\"*.png\")))\nj=0\nclasses = [\"without_mask\",\"mask_weared_incorrect\",\"with_mask\"]\nlabels = []\ndata = []\n\nprint(\"Extracting each data into respective label folders....\")\nfor idx,image in enumerate(image_directories):\n    img  = cv2.imread(image)\n    #scale to dimension\n    X,Y = df[\"Dimensions\"][idx]\n    cv2.resize(img,(int(X),int(Y)))\n    #find the face in each object\n    for obj in df.columns[3:]:\n        info = df[obj][idx]\n        if info!=0:\n            label = info[0]\n            info[0] = info[0].replace(str(label), str(classes.index(label)))\n            info=[int(each) for each in info]\n            face = img[info[2]:info[4],info[1]:info[3]]\n            if((info[3]-info[1])>40 and (info[4]-info[2])>40):\n                try:\n                    face = cv2.resize(face, (224, 224))\n                    face = img_to_array(face)\n                    face = preprocess_input(face)\n                    data.append(face)\n                    labels.append(label)\n                    if(label==\"mask_weared_incorrect\"):\n                        data.append(face)\n                        labels.append(label)\n\n                except:\n                    pass\n\n\n                \nprint(\"Done!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.array(data, dtype=\"float32\")\nlabels = np.array(labels)\nlabels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb = LabelEncoder()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = ImageDataGenerator(\n    zoom_range=0.1,\n    rotation_range=25,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n\tinput_tensor=Input(shape=(224, 224, 3)))\n\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(64, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(3, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INIT_LR = 1e-4\nEPOCHS = 50\nBS = 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(trainX, testX, trainY, testY) = train_test_split(data, labels,\n\ttest_size=0.3, stratify=labels, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])\n\n# train the head of the network\nprint(\"[INFO] training head...\")\nH = model.fit(\n\taug.flow(trainX, trainY, batch_size=BS),\n\tsteps_per_epoch=len(trainX) // BS,\n\tvalidation_data=(testX, testY),\n\tvalidation_steps=len(testX) // BS,\n\tepochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=32)\n\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n\n# show a nicely formatted classification report\nprint(classification_report(testY.argmax(axis=1), predIdxs,\n\ttarget_names=lb.classes_))\n\n# serialize the model to disk\nprint(\"[INFO] saving mask detector model...\")\n\n# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}